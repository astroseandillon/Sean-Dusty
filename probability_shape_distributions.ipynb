{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bb7cf89",
   "metadata": {},
   "source": [
    "# Calculating the absorption and scattering cross section using a probability distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "935d1248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# AA = time.time()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.integrate as spit\n",
    "import os\n",
    "print('hello world')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8ff311",
   "metadata": {},
   "source": [
    "### This defines the probability distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f45fc3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "def probability(dis_name, l1, l2, lmin=0.05, m1=0, m2=0, d=0):\n",
    "    '''\n",
    "    This is the probability distribution as a function of L1 and L2, the \n",
    "    geometric parameters. This parameter gets inserted into the integral that \n",
    "    calculates the average polarizability per unit volume\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dis_name : String\n",
    "        This specifies the distribution we will be using. \n",
    "        'CDE' = Continuous Distribution of Ellipsoids\n",
    "        'ERCDE' = Externally Restricted CDE, returns CDE if lmin=0\n",
    "        'tCDE' = truncated CDE, REQUIRES MORE WORK\n",
    "    l1 : Float\n",
    "        Largest Geometric Constant, lmin<l1<1.0\n",
    "    l2 : Float\n",
    "        Second Largest Geometric Constant, lmin<l2<=l1\n",
    "    lmin : Float, optional\n",
    "        Minimum allowed geometric constant.  The default is 0.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Float\n",
    "        Function dependent on l1 and l2\n",
    "\n",
    "    '''\n",
    "    l3 = 1 - l1 - l2\n",
    "    if dis_name == 'CDE':\n",
    "        return 2\n",
    "    elif dis_name == 'CDE2':\n",
    "        return 120 * l1 * l2 * l3\n",
    "    elif dis_name == 'ERCDE':\n",
    "        return 2/((1 - (3*lmin))**2)\n",
    "    elif dis_name == 'tCDE':\n",
    "        return 1/((1-d-m2)*(1-m1-m2-d) - 0.5*((1-d-m2)**2) - m1**2)\n",
    "    else:\n",
    "        return True\n",
    "        \n",
    "    \n",
    "print('hello world')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe9a8fb",
   "metadata": {},
   "source": [
    "### I think it would be easier to make the tCDE its own function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74997615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_tCDE(m1,m2,d):\n",
    "    return 1/((1-d-m2)*(1-m1-m2-d) - 0.5*((1-d-m2)**2) - m1**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc5b2f5",
   "metadata": {},
   "source": [
    "### Now we define our volume function. v_avg is used to calculate sigma below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47c3f86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def volume_integrand_mrn(r, q):\n",
    "    v = r**(-q)\n",
    "    return v\n",
    "\n",
    "# UNITS ARE IN MICRONS\n",
    "rmin = 0.005\n",
    "rmax = 0.25\n",
    "q = 3.5\n",
    "\n",
    "r_integral = spit.quad(volume_integrand_mrn, rmin, rmax, args=q)\n",
    "r_average = ((1/(rmax - rmin)) * r_integral[0])**(1/-q)\n",
    "v_avg = (4./3.) * np.pi * r_average**3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba15ca05",
   "metadata": {},
   "source": [
    "### creates function that calculates Sigma, defined in eq 13 in Min et al 2003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2fc664a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "def sigma(m, lamda, v):\n",
    "    sig = []\n",
    "    for i in range(len(lamda)):\n",
    "        k = (2.0 * np.pi)/lamda[i]\n",
    "        term1 = (6.0*np.pi) / (v * (k**3))\n",
    "        term2 = np.imag((m[i]**2))\n",
    "        term3 = 1.0 / abs(m[i]**2 - 1)**2\n",
    "        sig.append(term1 * term2 * term3)\n",
    "    return sig\n",
    "print('hello world')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3c1396",
   "metadata": {},
   "source": [
    "### creates our bounds for our geometric factors. The bounds are the sides of a triangle in (l1, l2) space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b28b2101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "def bounds_l1():\n",
    "    return [0,1]\n",
    "\n",
    "def bounds_l2(l1):\n",
    "    return [0,1-l1]\n",
    "print('hello world')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d2ac26",
   "metadata": {},
   "source": [
    "### This is where we calculate the absorption cross-section (Cabs). It creates an empty list, then calculates Cabs for a given distribution at each wavelength as described in Min 03, eqn 15. It then uses this to find the shape averaged mass absorption coefficient for particles of a given volume, as described in Min 03, eqn 39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36d4d2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cabs(m, dis_name, bounds_l2, bounds_l1):\n",
    "    cabs = []\n",
    "    if dis_name=='spheres':\n",
    "        for j in range(len(m)):\n",
    "            cabs.append(np.imag(3*(m[j]**2 - 1)/(m[j]**2 + 2)))\n",
    "    else:\n",
    "        for j in range(len(m)):\n",
    "            def f(l1, l2, n=m[j], dis_name='CDE'):\n",
    "                b = 1/(n**2 - 1)\n",
    "                term1 = 1/3 * 1/(b + l1)\n",
    "                term2 = 1/3 * 1/(b + l2)\n",
    "                term3 = 1/3 * 1/(b + 1 - l1 - l2)\n",
    "            # r = np.real((term1 + term2 + term3)*probability(dis_name, l1, l2))\n",
    "                j = np.imag((term1 + term2 + term3)*probability(dis_name, l1, l2))\n",
    "                return j\n",
    "            # return np.real((term1 + term2 + term3)*probability(dis_name, l1, l2)) + np.imag((term1 + term2 + term3)*probability(dis_name, l1, l2))\n",
    "            cabs.append(spit.nquad(f, [bounds_l2, bounds_l1])[0])\n",
    "    return cabs\n",
    "\n",
    "# j = cabs(m, 'spheres', bounds_l2, bounds_l1)\n",
    "# # dust = 'grph1-dl.nk'                  #DUST NAME HERE #grf\n",
    "# # rho = 3.33 #grams cm**-3            #density\n",
    "# # pathy = os.path.join(nk_path, dust) #pipeline is open\n",
    "# # wavelen, n_dust, k_dust = np.loadtxt(pathy, skiprows=7, unpack=True)\n",
    "# #                                     #lamda, n, and k values are extracted\n",
    "# # m = np.array([complex(n_dust[i], k_dust[i]) for i in range(len(wavelen))])\n",
    "# k = cabs(m, 'CDE', bounds_l2, bounds_l1)\n",
    "\n",
    "# print(j)\n",
    "# # print('')\n",
    "# print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac35618d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Specify which dust we are using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "976b04e2-21b2-4875-a4af-c36ab384cbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dustlist = [('oliv_nk_x.nk', 'spheres'), ('oliv_nk_y.nk', 'spheres'), ('oliv_nk_z.nk', 'spheres')]\n",
    "namelist = [dustlist[j][0][:-3]+dustlist[j][1]+'.dat' for j in range(len(dustlist))]\n",
    "weightlist = [1.0, 1.0, 1.0]\n",
    "dust_dir = ['/home/physics/Research/DUSTY/DUSTY/Lib_nk/', \n",
    "            \"C:/UTSA/Research/DUSTY/DUSTY/Lib_nk/\",\n",
    "           \"C:/Users/uhe082/OneDrive - University of Texas at San Antonio/Lib_nk\"]\n",
    "# this is the possible locations of where dust can be\n",
    "\n",
    "\n",
    "nk_path = dust_dir[0]               #where the dust is \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46361663-ea83-4f41-a693-83366f7e20a8",
   "metadata": {},
   "source": [
    "# Calculate the absorption and scattering arrays for each dust at each dust shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0792f92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(dustlist)):\n",
    "    pathy = os.path.join(nk_path, dustlist[j][0]) #pipeline is open\n",
    "    wavelen, n_dust, k_dust = np.loadtxt(pathy, skiprows=7, unpack=True)\n",
    "    m = np.array([complex(n_dust[i], k_dust[i]) for i in range(len(wavelen))])\n",
    "    cab = cabs(m, dustlist[j][1], bounds_l2, bounds_l1)\n",
    "    Cabs_array = np.array((cab))\n",
    "    Cabs_array *= (2 * np.pi / (wavelen)) * v_avg\n",
    "    sig = np.array((sigma(m, wavelen, v_avg)))\n",
    "    Csca_array = Cabs_array/sig\n",
    "    output = np.transpose((wavelen, Cabs_array, Csca_array))\n",
    "    f = open(dustlist[j][0][:-3]+dustlist[j][1]+'.dat', 'w')\n",
    "    for i in range(len(output)):\n",
    "        f.write(f\"{output[i,0]} \\t {output[i,1]} \\t {output[i,2]}\\n\")\n",
    "    f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b876fae6-8abb-428f-ab52-1137396bc351",
   "metadata": {},
   "source": [
    "# Making everything into the same array size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c54e7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "lam_final = np.geomspace(0.2, 500, num=500)\n",
    "total_array = np.ndarray((3,len(lam_final),len(dustlist)))\n",
    "total_array[:,:,0] = lam_final\n",
    "\n",
    "for k in range(len(namelist)):\n",
    "    lam, cabs_tot, csca_tot = np.loadtxt(namelist[k], unpack=True)\n",
    "    total_array[k,:,1] = np.interp(lam_final, lam, cabs_tot)\n",
    "    total_array[k,:,2] = np.interp(lam_final, lam, csca_tot)\n",
    "    h = open('tot array {}.txt'.format(k), 'w')\n",
    "    for b in range(len(lam_final)):\n",
    "        h.write(f\"{total_array[k,b,0]} \\t {total_array[k,b,1]} \\t {total_array[k,b,2]} \\n \")\n",
    "\n",
    "h.close()\n",
    "\n",
    "avg_array = np.ndarray((len(lam_final),3))\n",
    "avg_array[:,0] = lam_final\n",
    "for j in range(len(lam_final)):\n",
    "    avg_array[j,1] = np.average(total_array[:,j,1], weights=weightlist)\n",
    "    avg_array[j,2] = np.average(total_array[:,j,2], weights=weightlist)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "k = open('avg array.txt', 'w')\n",
    "for i in range(len(avg_array)):\n",
    "    k.write(f\"{avg_array[i,0]} \\t {avg_array[i,1]} \\t {avg_array[i,2]}\\n\")\n",
    "k.close()   \n",
    "    \n",
    "    \n",
    "    \n",
    "print('hello world')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5587b196-38f7-485f-a72d-a158c0916e0d",
   "metadata": {},
   "source": [
    "# Outputting into a single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10ffc7e4-fbbf-4bd5-90f2-4e288cead344",
   "metadata": {},
   "outputs": [],
   "source": [
    "titlestring=''\n",
    "for g in range(len(namelist)):\n",
    "    titlestring += namelist[g][:3] + str(weightlist[g]).replace('.','')\n",
    "    \n",
    "f = open(titlestring+'.dat','w')\n",
    "for i in range(len(lam_final)):\n",
    "    f.write(f\"{avg_array[i,0]} \\t {avg_array[i,1]} \\t {avg_array[i,2]}\\n\")\n",
    "f.close() \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4dc35e-3f79-4e28-b649-e6f1b18055ed",
   "metadata": {},
   "source": [
    "# Seeing what we got"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94efd386",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfig, ax = plt.subplots()\\ntitle = 'Fab test '\\nax.set(xscale='log', yscale='log')\\nax.set_title(title, fontsize=16)\\nax.set_xlabel(r'$\\\\lambda (\\\\mu m)$', fontsize=14)\\nax.set_ylabel(r'$<C_{abs}>$ cm$^{2}$ g$^{-1}$', fontsize=14)\\n# ax.plot(lam_old, cab_old, label='our data')\\nax.plot(x,y, label='Fab fig 7')\\n# ax.plot(wavelen, np.array((cabs_ercde)), label='ERCDE')\\nax.legend()\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lam_new, cab_new, csa_new = \n",
    "# x,y = np.loadtxt('cde1_fab01_fig7_olivine.csv', delimiter='\\l',unpack=True, skiprows=1, usecols=[0,1])\n",
    "# lam_old, cab_old, csa_old = np.loadtxt('oli10oli10oli10.dat', unpack=True)\n",
    "data=np.loadtxt('cde1_fab01_fig7_olivine.csv',usecols=[0,1],skiprows=8, delimiter=',')\n",
    "\n",
    "'''\n",
    "fig, ax = plt.subplots()\n",
    "title = 'Fab test '\n",
    "ax.set(xscale='log', yscale='log')\n",
    "ax.set_title(title, fontsize=16)\n",
    "ax.set_xlabel(r'$\\lambda (\\mu m)$', fontsize=14)\n",
    "ax.set_ylabel(r'$<C_{abs}>$ cm$^{2}$ g$^{-1}$', fontsize=14)\n",
    "# ax.plot(lam_old, cab_old, label='our data')\n",
    "ax.plot(x,y, label='Fab fig 7')\n",
    "# ax.plot(wavelen, np.array((cabs_ercde)), label='ERCDE')\n",
    "ax.legend()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7fbaad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f441ab33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
